{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNIPNglOA2zYNXV4ye83eg4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "47d7ea1375844c53ba4b5f25fe0db810": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b42f6f289c034efeb0e5696171e17330",
       "IPY_MODEL_766cc6cc3bc94bc6afa591c4a09e337f",
       "IPY_MODEL_d132acf10a9c451e865047355efac840"
      ],
      "layout": "IPY_MODEL_44bb7f8cb78347209844bb2463e1a8be"
     }
    },
    "b42f6f289c034efeb0e5696171e17330": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69581083f3114faba53831a062b4410d",
      "placeholder": "​",
      "style": "IPY_MODEL_7ca2a2fad6894e41b61f24f108e29673",
      "value": "파일별 문제점 평가 진행:   0%"
     }
    },
    "766cc6cc3bc94bc6afa591c4a09e337f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15f72fc27a544278b69d7d08f91eb781",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3994845a159842389e163f37ec28102b",
      "value": 0
     }
    },
    "d132acf10a9c451e865047355efac840": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b77534256c7e4eeabf499a9fa480679f",
      "placeholder": "​",
      "style": "IPY_MODEL_cfb735fd7eff413bab561291ef9e19d1",
      "value": " 0/3 [00:04&lt;?, ?it/s]"
     }
    },
    "44bb7f8cb78347209844bb2463e1a8be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69581083f3114faba53831a062b4410d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ca2a2fad6894e41b61f24f108e29673": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15f72fc27a544278b69d7d08f91eb781": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3994845a159842389e163f37ec28102b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b77534256c7e4eeabf499a9fa480679f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfb735fd7eff413bab561291ef9e19d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Prompt 생성\n",
    "\n",
    "\n",
    "> **주제: 한국 보험 약관의 해석 및 비판적 분석** <br/><br/>\n",
    "Topic: Interpretation and critical analysis of Korean insurance terms"
   ],
   "metadata": {
    "id": "6ZWyEpERjvs5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: 문제점 '평가' 및 중요 문제 선정 (ToT 평가, RAG 활용 가능)\n",
    "\n",
    "### 목표: 발상된 문제점 후보들을 중요도 기준으로 평가하고 최적을 선정하는 것. 평가 기준을 판단할 때 RAG로 추가 정보를 얻으면 더 객관적인 평가 가능.\n",
    "### 수정 내용:\n",
    "* 문제점 후보들을 평가할 때, 각 문제점과 관련된 약관 원문 및 Step 2에서 문제점 발상 시 사용되었던 외부 참고 자료와 함께 GPT 프롬프트에 넣음\n",
    "\n",
    "* 프롬프트 지침에 \"제시된 문제점 후보와 관련 약관 및 **[참고 자료]**를 바탕으로 심각성, 발생 가능성, 모호성 등을 평가하라\"고 명시\n",
    "* 평가 기준(심각성, 발생 가능성 등)을 판단할 때 RAG로 검색된 새로운 외부 정보 (예: 특정 문제점 유형에 대한 최근 통계, 최신 법원 판례 등)를 추가로 제공하여 평가의 정확성을 높일 수 있음 (평가 단계마다 검색해야 해서 복잡해질 수 있음)\n",
    "\n",
    "* 평가 결과를 JSON으로 받고, 총점 기준으로 순위 매겨 최적 문제점을 선정하는 것은 동일.\n",
    "----"
   ],
   "metadata": {
    "id": "HvRlhvY6jnGc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rBDUauLcrkz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275131093,
     "user_tz": -540,
     "elapsed": 52794,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "c245ff02-ba52-45e5-96c1-e70005546290"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.63)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.44)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
      "Collecting langchain-core<1.0.0,>=0.3.59 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.84.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.5)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-4.4.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.34.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.3/67.3 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.72.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.32.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.22.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m34.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_openai-0.3.21-py3-none-any.whl (65 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.2/65.2 kB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.3/19.3 MB\u001B[0m \u001B[31m82.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.9/94.9 kB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.1/24.1 MB\u001B[0m \u001B[31m74.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m284.2/284.2 kB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m68.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m438.1/438.1 kB\u001B[0m \u001B[31m25.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.0/363.0 kB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.6/101.6 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.4/16.4 MB\u001B[0m \u001B[31m89.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_api-1.34.0-py3-none-any.whl (65 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.8/65.8 kB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.34.0-py3-none-any.whl (55 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.7/55.7 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl (196 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.2/196.2 kB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_util_http-0.55b0-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.34.0-py3-none-any.whl (118 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m118.4/118.4 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-4.4.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.7/98.7 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.4/44.4 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m459.8/459.8 kB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.9/50.9 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m71.5/71.5 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/4.0 MB\u001B[0m \u001B[31m87.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m454.8/454.8 kB\u001B[0m \u001B[31m26.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=8809ef145b04c410128aa0b6bb999ac1f8c6ec6fd0fabc96aa04a3f6d13ecf11\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, PyMuPDF, overrides, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, langsmith, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, opentelemetry-instrumentation-fastapi, langchain-community, chromadb, langchain-chroma\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.46.2\n",
      "    Uninstalling starlette-0.46.2:\n",
      "      Successfully uninstalled starlette-0.46.2\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.44\n",
      "    Uninstalling langsmith-0.3.44:\n",
      "      Successfully uninstalled langsmith-0.3.44\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.115.12\n",
      "    Uninstalling fastapi-0.115.12:\n",
      "      Successfully uninstalled fastapi-0.115.12\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.63\n",
      "    Uninstalling langchain-core-0.3.63:\n",
      "      Successfully uninstalled langchain-core-0.3.63\n",
      "Successfully installed PyMuPDF-1.26.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.12 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-32.0.1 langchain-chroma-0.2.4 langchain-community-0.3.24 langchain-core-0.3.64 langchain-openai-0.3.21 langsmith-0.3.45 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 onnxruntime-1.22.0 opentelemetry-api-1.34.0 opentelemetry-exporter-otlp-proto-common-1.34.0 opentelemetry-exporter-otlp-proto-grpc-1.34.0 opentelemetry-instrumentation-0.55b0 opentelemetry-instrumentation-asgi-0.55b0 opentelemetry-instrumentation-fastapi-0.55b0 opentelemetry-proto-1.34.0 opentelemetry-sdk-1.34.0 opentelemetry-semantic-conventions-0.55b0 opentelemetry-util-http-0.55b0 overrides-7.7.0 posthog-4.4.0 pydantic-settings-2.9.1 pypika-0.48.9 python-dotenv-1.1.0 starlette-0.45.3 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community langchain-openai chromadb PyMuPDF langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fZb91HrjYne",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275165850,
     "user_tz": -540,
     "elapsed": 26577,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "634e841b-93e1-4a37-b15c-d14d55057997"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import tiktoken\n",
    "import time\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from google.colab import userdata\n",
    "from collections import defaultdict # 평가 함수 등에 필요"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Langchain 관련 임포트 (최신 langchain-chroma 및 langchain-openai 사용)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma # <-- 최신 임포트 경로 확인!\n",
    "import openai\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.documents import Document"
   ],
   "metadata": {
    "id": "iuHlYdh2kzSU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275176599,
     "user_tz": -540,
     "elapsed": 2669,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"OpenAI API 키 설정 확인 중 (userdata 사용)\")\n",
    "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
    "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = x\n",
    "client = openai.OpenAI(api_key = userdata.get('OPENAI_API_KEY'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkAp3EMnlHNP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275188759,
     "user_tz": -540,
     "elapsed": 3410,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "95f60ac6-a2da-48eb-c0bf-fa68b9a24b94"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OpenAI API 키 설정 확인 중 (userdata 사용)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if openai_api_key is None:\n",
    "    print(\"!!! 오류: Colab '비밀'에서 'OPENAI_API_KEY'를 가져오지 못했습니다. !!!\")\n",
    "    print(\"이 노트북에서도 Colab 왼쪽의 자물쇠 아이콘(비밀)에서 'OPENAI_API_KEY' 이름으로 키를 설정해주세요.\")\n",
    "    print(\"API 키 없이는 임베딩 모델 로드 및 GPT 모델 호출이 불가능합니다.\")\n",
    "    # API 키 없이는 임베딩 모델 로드 및 GPT 호출이 불가능하므로 관련 객체는 None\n",
    "    embeddings = None\n",
    "    llm = None\n",
    "    rag_vectorstore = None # 로드 불가\n",
    "else:\n",
    "    print(\"OpenAI API 키 설정 완료.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YST_9V0-ob3d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275202190,
     "user_tz": -540,
     "elapsed": 161,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "a0903b85-e0df-485e-83b3-796b54c96b9f"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OpenAI API 키 설정 완료.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 임베딩 모델 로드 (벡터 스토어 로드 시 필요)\n",
    "# Step 0에서 사용했던 모델과 동일해야 합니다.\n",
    "try:\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    print(\"OpenAI 임베딩 모델 준비 완료.\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! 오류: 임베딩 모델 로드 오류: {e} !!!\")\n",
    "    print(\"환경 변수에 설정된 API 키가 유효한지, 모델 이름이 올바른지 확인하세요.\")\n",
    "    embeddings = None"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djMpy05AlHRC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275205951,
     "user_tz": -540,
     "elapsed": 1011,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "f9a15eb0-d528-441a-b9b1-ed963aad08bb"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OpenAI 임베딩 모델 준비 완료.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# GPT 모델 준비 (평가 시 필요)\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-2024-05-13\", temperature=0.0) # 평가 단계는 temperature 낮게\n",
    "    print(f\"GPT 모델 준비 완료: {llm.model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! 오류: GPT 모델 로드 오류: {e} !!!\")\n",
    "    print(\"환경 변수에 설정된 API 키가 유효한지, 모델 이름이 올바른지 확인하세요.\")\n",
    "    llm = None"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RU1WLIkYD183",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275207178,
     "user_tz": -540,
     "elapsed": 132,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "c1490669-3e04-4194-cb4a-30065663f12c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPT 모델 준비 완료: gpt-4o-2024-05-13\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Step 2 결과 JSON 파일들이 모여 있는 폴더 경로 ---\n",
    "step2_results_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/step2_results\" # 예시 경로\n",
    "\n",
    "# --- 약관 원문 파일들이 모여 있는 폴더 경로 ---\n",
    "terms_original_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/data/보험약관\" # 예시 경로\n",
    "\n",
    "# --- 약관 요약본 파일들이 모여 있는 폴더 경로 ---\n",
    "summary_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/data/보험약관/summary\" # 예시 경로\n",
    "\n",
    "# --- Step 3 평가 결과 저장 폴더 경로 ---\n",
    "save_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/step3_results\" # 예시 경로\n",
    "\n",
    "\n",
    "# --- 벡터 스토어 영구 저장 경로 ---\n",
    "PERSIST_DIRECTORY = '/content/drive/MyDrive/PROJECT/cn_api_project/chroma_db' # 예시 경로"
   ],
   "metadata": {
    "id": "oKW35L0gTxss",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275209783,
     "user_tz": -540,
     "elapsed": 43,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 벡터 스토어 영구 저장 경로 지정 ---\n",
    "# 첫 번째 노트북에서 벡터 스토어를 저장했던 그 경로와 동일해야 합니다.\n",
    "PERSIST_DIRECTORY = '/content/drive/MyDrive/PROJECT/cn_api_project/chroma_db' # 예시 경로\n",
    "\n",
    "# --- 벡터 스토어 로드 ---\n",
    "rag_vectorstore = None # 초기화\n",
    "# 임베딩 모델이 성공적으로 로드되었고 (API 키가 설정되었고) 저장 경로가 존재하면 로드 시도\n",
    "if embeddings is not None and os.path.exists(PERSIST_DIRECTORY):\n",
    "    print(f\"\\n--- 벡터 스토어 로드 중: '{PERSIST_DIRECTORY}' ---\")\n",
    "    try:\n",
    "        rag_vectorstore = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)\n",
    "        print(\"벡터 스토어 로드 완료.\")\n",
    "        print(f\"로드된 청크 개수: {rag_vectorstore._collection.count()}\") # 로드된 청크 개수 확인!\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! 오류: 벡터 스토어 로드 중 오류 발생 !!!\")\n",
    "        print(f\"오류 내용: {e}\")\n",
    "        print(f\"경로 확인: '{PERSIST_DIRECTORY}'에 파일 있는지, 로드 시 사용한 임베딩 모델이 올바른지 확인하세요.\")\n",
    "        rag_vectorstore = None\n",
    "else:\n",
    "    if embeddings is None:\n",
    "        print(\"\\n!!! 벡터 스토어 로드 불가: 임베딩 모델 로드 오류 (API 키 확인 필요). !!!\")\n",
    "    elif not os.path.exists(PERSIST_DIRECTORY):\n",
    "         print(f\"\\n!!! 벡터 스토어 로드 불가: 저장 폴더를 찾을 수 없습니다 - '{PERSIST_DIRECTORY}' !!!\")\n",
    "         print(\"첫 번째 노트북에서 Step 0을 실행하여 벡터 스토어를 해당 경로에 저장했는지 확인해주세요.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R05Mh8RTQ3AS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275235315,
     "user_tz": -540,
     "elapsed": 23732,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "ab113425-88ec-4201-be57-aa13a7d30780"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- 벡터 스토어 로드 중: '/content/drive/MyDrive/PROJECT/cn_api_project/chroma_db' ---\n",
      "벡터 스토어 로드 완료.\n",
      "로드된 청크 개수: 37249\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Step 2 결과 JSON 파일 경로 지정 ---\n",
    "# Step 2 노트북에서 결과를 저장했던 그 경로와 파일 이름과 동일해야 합니다.\n",
    "step2_results_save_dir = '/content/drive/MyDrive/PROJECT/cn_api_project/step2_results' # 예시 경로\n"
   ],
   "metadata": {
    "id": "Sl9IJbFrlHVB",
    "collapsed": true,
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275241164,
     "user_tz": -540,
     "elapsed": 57,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"\\n--- Step 2 결과 JSON 파일들 로드 중 (디렉토리: '{step2_results_save_dir}') ---\")\n",
    "# 모든 문제점 후보 데이터를 담을 리스트\n",
    "all_loaded_problem_candidates = []\n",
    "# 디렉토리 순회\n",
    "if os.path.exists(step2_results_save_dir):\n",
    "    json_files = [f for f in os.listdir(step2_results_save_dir) if f.endswith('.json')]\n",
    "\n",
    "    if not json_files:\n",
    "        print(\"⚠️ JSON 파일이 존재하지 않습니다.\")\n",
    "    else:\n",
    "        for json_file in json_files:\n",
    "            file_path = os.path.join(step2_results_save_dir, json_file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    all_loaded_problem_candidates.extend(data)\n",
    "\n",
    "                print(f\"✅ '{json_file}' 로드 완료 - 문제점 후보 수: {len(data)}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ '{json_file}' 로드 실패 - 오류: {e}\")\n",
    "else:\n",
    "    print(f\"❌ 디렉토리를 찾을 수 없습니다: '{step2_results_save_dir}'\")\n",
    "\n",
    "print(f\"\\n총 로드된 문제점 후보 개수: {len(all_loaded_problem_candidates)}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8-ou7ohQZdX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275243811,
     "user_tz": -540,
     "elapsed": 760,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "cddd99aa-63ef-41a1-8339-20d8acd543a2"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Step 2 결과 JSON 파일들 로드 중 (디렉토리: '/content/drive/MyDrive/PROJECT/cn_api_project/step2_results') ---\n",
      "✅ 'problems_한화_스마일펫보험.json' 로드 완료 - 문제점 후보 수: 227\n",
      "✅ 'problems_삼성_다이렉트_실손보험.json' 로드 완료 - 문제점 후보 수: 442\n",
      "✅ 'problems_삼성화재_반려묘보험_의기냥냥.json' 로드 완료 - 문제점 후보 수: 308\n",
      "\n",
      "총 로드된 문제점 후보 개수: 977\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 헬퍼 함수"
   ],
   "metadata": {
    "id": "3p2I_HDqorzr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 파일 로드 헬퍼 함수 추가 ---\n",
    "# 텍스트 파일 로드 함수\n",
    "def load_text_file(file_path):\n",
    "    \"\"\"지정된 경로의 텍스트 파일 내용을 읽어 반환합니다.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: 파일 로드 중 오류 발생 ('{os.path.basename(file_path)}'): {e}\")\n",
    "    return text"
   ],
   "metadata": {
    "id": "YPYW4MAsT1VR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275251129,
     "user_tz": -540,
     "elapsed": 22,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# JSON 파일 로드 함수 (Step 2 결과 파일 로드용)\n",
    "def load_json_file(file_path):\n",
    "    \"\"\"지정된 경로의 JSON 파일 내용을 읽어 반환합니다.\"\"\"\n",
    "    data = None\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: JSON 파일 로드 또는 파싱 중 오류 발생 ('{os.path.basename(file_path)}'): {e}\")\n",
    "    return data"
   ],
   "metadata": {
    "id": "HyMkWzQioqyB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275254674,
     "user_tz": -540,
     "elapsed": 23,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# request_gpt 헬퍼 함수\n",
    "def request_gpt(message, model=\"gpt-4o-2024-05-13\", temperature=0.0, type=\"json_object\"):\n",
    "     if client is None:\n",
    "          print(\"API 클라이언트가 초기화되지 않습니다.\")\n",
    "          return {} if type == \"json_object\" else \"API 클라이언트 오류\"\n",
    "     messages = [{\"role\": \"user\", \"content\": message}]\n",
    "     try:\n",
    "        response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    response_format={\"type\" : type}\n",
    "                ).model_dump()\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        if type == \"json_object\":\n",
    "            content = content.strip()\n",
    "            if content.startswith(\"```json\"): content = content[7:]\n",
    "            if content.endswith(\"```\"): content = content[:-3]\n",
    "            content = content.strip()\n",
    "            return json.loads(content)\n",
    "        else: return content\n",
    "     except Exception as e:\n",
    "          print(f\"!!! 오류: API 호출 중 오류 발생: {e} !!!\")\n",
    "          return {} if type == \"json_object\" else f\"API Error: {e}\""
   ],
   "metadata": {
    "id": "lxT9S9u2owSf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275256678,
     "user_tz": -540,
     "elapsed": 32,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_problem_candidates(step2_results_folder):\n",
    "    problem_candidates = []\n",
    "    for json_file in glob.glob(os.path.join(step2_results_folder, \"*.json\")):\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                problem_candidates.extend(data)\n",
    "            else:\n",
    "                problem_candidates.append(data)\n",
    "    print(f\"✅ 문제점 후보 {len(problem_candidates)}개 로딩 완료\")\n",
    "    return problem_candidates\n",
    "\n",
    "def load_summary_and_original_text(summary_file_path, terms_folder):\n",
    "    with open(summary_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        summary_text = f.read()\n",
    "    common_prefix = os.path.basename(summary_file_path).replace(\"_summary.txt\", \"\")\n",
    "    original_file_path = os.path.join(terms_folder, f\"{common_prefix}.txt\")\n",
    "\n",
    "    if os.path.exists(original_file_path):\n",
    "        with open(original_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            original_text = f.read()\n",
    "        print(f\"✅ 약관 원문 로딩 성공: {original_file_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"❌ 약관 원문 파일 없음: {original_file_path}\")\n",
    "\n",
    "    return summary_text, original_text, os.path.basename(summary_file_path)\n",
    "\n",
    "# 텍스트를 토큰 기준으로 n개 이하로 분할하는 유틸 함수\n",
    "def split_text_by_token_limit(text, token_limit=1500, model=\"gpt-4\"):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    tokens = enc.encode(text)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), token_limit):\n",
    "        chunk_tokens = tokens[i:i+token_limit]\n",
    "        chunk_text = enc.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    print(f\"✅ 텍스트 분할 완료: 총 {len(chunks)}개 청크 생성 (청크당 {token_limit}토큰 이하)\")\n",
    "    return chunks"
   ],
   "metadata": {
    "id": "dju9eEcQTcuO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275259350,
     "user_tz": -540,
     "elapsed": 17,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 변수"
   ],
   "metadata": {
    "id": "YXt3Z8prjnbm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275262447,
     "user_tz": -540,
     "elapsed": 37,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "metadata": {
    "id": "BqOGMUoZRUEm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275263477,
     "user_tz": -540,
     "elapsed": 90,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 텍스트 분할 (필요시)\n",
    "summary_chunks = split_text_by_token_limit(summary_text, token_limit=1000)\n",
    "original_chunks = split_text_by_token_limit(original_text, token_limit=1000)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "E54tseWMYN3M",
    "executionInfo": {
     "status": "error",
     "timestamp": 1749275265402,
     "user_tz": -540,
     "elapsed": 154,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "79266d83-407e-4add-a624-fb01ca75e022"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'summary_text' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-b502e7f7cedd>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# 텍스트 분할 (필요시)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0msummary_chunks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit_text_by_token_limit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msummary_text\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtoken_limit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0moriginal_chunks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit_text_by_token_limit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal_text\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtoken_limit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'summary_text' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_evaluation_results = []"
   ],
   "metadata": {
    "id": "PHSV1FtPYS8U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275267516,
     "user_tz": -540,
     "elapsed": 64,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. 문제점 후보를 수량 기준 분할 (예: 50개씩)\n",
    "def split_list(lst, chunk_size):\n",
    "    return [lst[i:i+chunk_size] for i in range(0, len(lst), chunk_size)]"
   ],
   "metadata": {
    "id": "XhoSFOd7UEdl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275268512,
     "user_tz": -540,
     "elapsed": 63,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 프롬프트"
   ],
   "metadata": {
    "id": "f95zn6JkpeaC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Step 3 - 문제점 평가 프롬프트 템플릿 (ToT 평가 + RAG Context 포함) ---\n",
    "evaluation_template_problem_rag = \"\"\"\n",
    "## 역할: 소비자 보호 관점에서 보험 약관의 잠재적 문제점을 평가하는 전문 분석가\n",
    "\n",
    "## 임무:\n",
    "아래 **[잠재적 문제점 후보들]** 목록을 **[분석 대상 약관 원문 텍스트]**, **[이전 약관 전체 요약]**, 그리고 **[추가 참고 자료]**를 모두 종합하여 평가하고, 각 문제점 후보가 얼마나 중요하고 현실적인 문제인지 아래 JSON 형식으로 평가 결과를 반환해 주세요. 가장 중요하고 시급히 개선해야 할 문제점을 선별하기 위한 객관적인 평가를 수행합니다.\n",
    "이 평가는 보험 약관의 개선 방향을 결정하기 위한 중요한 작업이며, **소비자 피해를 예방하고 분쟁을 줄이기 위한 목적**을 가지고 있습니다.\n",
    "\n",
    "[잠재적 문제점 후보들 (JSON 문자열)]:\n",
    "{problem_candidates_json_string}\n",
    "\n",
    "[분석 대상 약관 원문 텍스트]:\n",
    "{analysis_target_text}\n",
    "\n",
    "[이전 약관 전체 요약]:\n",
    "{previous_full_summary}\n",
    "\n",
    "[추가 참고 자료]:\n",
    "{rag_context}\n",
    "\n",
    "## 평가 기준 (각 기준별로 10점 만점 부여):\n",
    "1.  **문제의 심각성 (소비자 피해 규모):**\n",
    "    *   이 문제로 인해 소비자가 입을 수 있는 피해가 얼마나 큰가요? (예: 전액 보험금 미지급, 계약 해지 등일수록 고득점)\n",
    "    *   이 문제점이 실제로 발생했을 때 소비자가 입을 수 있는 **잠재적 피해의 크기**를 평가합니다. (예: 보험금 전액 미지급, 거액의 손실, 계약 해지 등 심각한 피해일수록 높은 점수)\n",
    "    *   단순한 불편함이나 오해를 넘어 실질적인 재산상/법적 손실 가능성을 중점적으로 고려합니다.\n",
    "2.  **실제 발생 가능성:**\n",
    "    *   해당 문제점 시나리오가 **현실에서 실제로 발생할 가능성이 얼마나 높은지**를 평가합니다. (예: 약관 문구가 모호하여 자주 분쟁이 발생하는 유형이거나, 소비자가 흔히 겪는 상황일수록 높은 점)\n",
    "    *   RAG 참고자료(분쟁사례, 과거 판례 등)를 적극 반영하여 실제 사례가 있으면 높게 평가하세요.\n",
    "    *   [추가 참고 자료]의 분쟁 사례나 피해 사례 등을 참고하여 과거에 유사한 문제가 실제로 발생한 적이 있는지 고려합니다. 법규 위반 가능성이 명확할수록 발생 가능성이 높다고 봅니다.\n",
    "3.  **약관 표현의 모호성 정도:**\n",
    "    *   약관 문구가 얼마나 불명확한가요?\n",
    "    *   해당 문제점을 유발하는 약관 문구나 조건이 **얼마나 불명확하고 여러 가지로 해석될 여지가 많은지**를 평가합니다. (예: 특정 용어 정의가 없거나 불분명한 경우, 보상/면책 조건이 애매모호한 경우 등 높은 점)\n",
    "    *   명확하게 숫자로 정해져 있거나 예시가 잘 제시된 경우는 모호성이 낮다고 봅니다. 모호성이 높을수록 소비자의 오해나 보험사의 자의적 해석으로 이어질 가능성이 큽니다.\n",
    "\n",
    "## 지침:\n",
    "1.  **후보 목록 검토:** [잠재적 문제점 후보들] 목록의 각 문제점 요약, 시나리오, 근거_및_추론과정, 관련 약관 표현 등을 꼼꼼히 읽어 각 문제점의 내용을 정확히 이해합니다.\n",
    "2.  **정보 종합 및 평가:** 각 문제점 후보에 대해 위에 제시된 3가지 **평가 기준**을 적용하여 평가를 수행합니다. **[분석 대상 약관 원문 텍스트]**에서 해당 문제점과 관련된 정확한 문구를 다시 확인하고, **[이전 약관 전체 요약]**으로 전체 맥락을 고려하며, **특히 [추가 참고 자료]**에 있는 분쟁 사례, 법규, 유사 약관 내용 등을 적극적으로 참고하여 각 기준별 점수를 **논리적으로** 결정합니다. (예: \"참고 자료의 금감원 사례를 보니 이 문제로 실제 피해 본 사람이 많아 발생 가능성이 높다고 판단.\")\n",
    "3.  **평가 이유 요약 (CoT 평가):** 각 문제점 후보에 대해 점수를 부여한 **구체적인 이유**를 '평가_이유_요약' 항목에 간략하게 설명합니다. **왜 그 점수를 주었는지, 어떤 약관 문구나 참고 자료가 판단의 근거가 되었는지**를 명확히 밝힙니다.\n",
    "                                각 점수에 대한 **구체적 이유**를 `평가_이유_요약`에 작성하세요.\n",
    "                                    - 예: “금감원 사례집에서 유사 피해 사례가 반복 발생하여 발생 가능성 높음”\n",
    "                                    - 약관 문구가 판단에 어떤 영향을 주었는지도 명시\n",
    "4.  **JSON 출력 형식:** 모든 문제점 후보에 대한 평가 결과를 아래 JSON 형식의 **리스트**로 반환합니다. 각 결과 항목의 'id'는 평가 대상 문제점 후보의 'id'와 **반드시 일치**해야 합니다. 각 평가 기준별 점수(정수형)와 총점(30점 만점, 자동 합산)을 정확히 포함합니다.\n",
    "5.  **평가 불가능 후보 처리:** 만약 정보 부족 등의 이유로 특정 문제점 후보를 평가하기 어렵다면, 해당 후보에 대해 모든 평가 기준에 **0점**을 부여하고 '평가_이유_요약'에 '정보 부족' 등으로 명시합니다.\n",
    "\n",
    "## 출력 형식:\n",
    "JSON\n",
    "\n",
    "## 출력 시작:\n",
    "```json\n",
    "{{\n",
    "    \"평가_결과\": [\n",
    "        {{\n",
    "            \"id\": <평가 대상 문제점 후보의 고유 ID (정수)>,\n",
    "            \"문제점_요약\": \"<평가 대상 문제점 요약 (원본 그대로 또는 간략히). 확인용.>\",\n",
    "            \"문제의_심각성\": <점수 (0-10)>,\n",
    "            \"실제_발생_가능성\": <점수 (0-10)>,\n",
    "            \"약관_표현의_모호성_정도\": <점수 (0-10)>,\n",
    "            \"총점\": <세 기준 점수의 합 (0-30)>,\n",
    "            \"평가_이유_요약\": \"<이 문제점에 대해 점수를 부여한 구체적인 이유. 어떤 약관 문구/참고 자료를 보고 이렇게 판단했는지 간략히 설명.>\"\n",
    "        }},\n",
    "        // ... 발상된 모든 문제점 후보에 대한 평가 결과 객체 추가 ...\n",
    "    ]\n",
    "}}\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "jK_zNbYkRKXb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275270591,
     "user_tz": -540,
     "elapsed": 81,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 문제점 평가 실행 함수"
   ],
   "metadata": {
    "id": "cMB3aRmmpi5-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_problems_with_rag(problem_candidates, analysis_target_text_full, previous_full_summary_text, rag_vectorstore, model=\"gpt-4o-2024-05-13\"):\n",
    "# \"\"\" RAG를 사용하여 발상된 문제점 후보들을 평가합니다. 약관/요약 전체 텍스트를 청크로 분할하여 프롬프트에 포함합니다. \"\"\"\n",
    "    if client is None:\n",
    "        print(\"\\n!!! API 클라이언트가 초기화되지 않아 문제점 평가를 실행할 수 없습니다. !!!\")\n",
    "        return []\n",
    "    if not problem_candidates:\n",
    "        print(\"\\n--- [Step 3] 문제점 평가 (평가할 후보 없음) ---\")\n",
    "        return []\n",
    "\n",
    "    # 평가 단계는 논리적인 평가를 위해 temperature를 낮게 설정 (0.0)\n",
    "    evaluation_temperature = 0.0\n",
    "\n",
    "    print(f\"\\n--- [Step 3] 잠재적 문제점 평가 ({len(problem_candidates)}개 후보 대상, RAG 활용 가능) ---\")\n",
    "\n",
    "    # --- 약관 원문 전체 텍스트를 평가 프롬프트에 맞게 청크 분할 ---\n",
    "    analysis_chunk_size = 2000 # 평가 프롬프트에 넣을 약관 청크 크기 (조절 가능)\n",
    "    analysis_chunk_overlap = 200 # 청크 간 겹침\n",
    "\n",
    "    analysis_text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=analysis_chunk_size,\n",
    "        chunk_overlap=analysis_chunk_overlap\n",
    "    )\n",
    "\n",
    "    analysis_text_chunks_list = []\n",
    "    if analysis_target_text_full:\n",
    "        try:\n",
    "            # Document 객체로 만들어 split\n",
    "            doc_to_split = Document(page_content=analysis_target_text_full, metadata={\"source\": \"원본 약관 전체\"})\n",
    "            analysis_text_chunks_docs = analysis_text_splitter.split_documents([doc_to_split])\n",
    "            analysis_text_chunks_list = [doc.page_content for doc in analysis_text_chunks_docs] # 청크 내용만 리스트로 추출\n",
    "            print(f\"약관 원문 전체 텍스트 ({len(analysis_target_text_full)}자) 평가용 청크 {len(analysis_text_chunks_list)}개 생성.\")\n",
    "        except Exception as e:\n",
    "            print(f\"!!! 오류: 약관 원문 텍스트 청크 분할 중 오류 발생: {e} !!!\")\n",
    "            # 오류 시 빈 리스트로 진행\n",
    "\n",
    "    # 청크 내용을 문자열로 합쳐서 프롬프트에 넣습니다. (각 청크를 구분자로 연결)\n",
    "    analysis_text_for_prompt = \"\\n---\\n\".join(analysis_text_chunks_list)\n",
    "\n",
    "\n",
    "    # --- 이전 약관 전체 요약 텍스트를 평가 프롬프트에 맞게 청크 분할 ---\n",
    "    summary_chunk_size = 1000 # 평가 프롬프트에 넣을 요약 청크 크기 (조절 가능)\n",
    "    summary_chunk_overlap = 100 # 청크 간 겹침\n",
    "\n",
    "    summary_text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=summary_chunk_size,\n",
    "        chunk_overlap=summary_chunk_overlap\n",
    "    )\n",
    "\n",
    "    previous_summary_chunks_list = []\n",
    "    if previous_full_summary_text:\n",
    "        try:\n",
    "            doc_to_split_summary = Document(page_content=previous_full_summary_text, metadata={\"source\": \"이전 약관 요약 전체\"})\n",
    "            previous_summary_chunks_docs = summary_text_splitter.split_documents([doc_to_split_summary])\n",
    "            previous_summary_chunks_list = [doc.page_content for doc in previous_summary_chunks_docs] # 청크 내용만 리스트로 추출\n",
    "            print(f\"이전 요약 전체 텍스트 ({len(previous_full_summary_text)}자) 평가용 청크 {len(previous_summary_chunks_list)}개 생성.\")\n",
    "        except Exception as e:\n",
    "            print(f\"!!! 오류: 이전 요약 텍스트 청크 분할 중 오류 발생: {e} !!!\")\n",
    "            # 오류 시 빈 리스트로 진행\n",
    "\n",
    "    # 청크 내용을 문자열로 합쳐서 프롬프트에 넣습니다. (각 청크를 구분자로 연결)\n",
    "    previous_summary_for_prompt = \"\\n---\\n\".join(previous_summary_chunks_list)\n",
    "\n",
    "    # --- 평가 관련 RAG 검색 (법규, 사례 등 참고 자료 검색) ---\n",
    "    rag_context_text = \"참고 자료 없음.\"\n",
    "    if rag_vectorstore is not None:\n",
    "        print(\"\\n--- 평가 관련 RAG 검색 시작 ---\")\n",
    "        try:\n",
    "            query_text = \"보험 약관 문제점 평가 기준: \" + \" \".join([p.get('문제점_요약', '') for p in problem_candidates if p.get('문제점_요약')])\n",
    "            if query_text.strip():\n",
    "                retriever = rag_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "                retrieved_docs = retriever.invoke(query_text[:300])\n",
    "                rag_context_text = \"\\n----\\n\".join([\n",
    "                    f\"출처: {doc.metadata.get('source', '알 수 없음')}, 페이지: {doc.metadata.get('page', '알 수 없음')}\\n{doc.page_content}\"\n",
    "                    for doc in retrieved_docs\n",
    "                ])\n",
    "                print(f\"평가 관련 RAG 검색 완료. 총 {len(retrieved_docs)}개의 참고 자료 확보.\")\n",
    "            else:\n",
    "                 print(\"평가 관련 RAG 검색 쿼리가 비어있습니다.\")\n",
    "                 rag_context_text = \"쿼리 비어있음: 참고 자료 검색 불가\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"!!! 오류: 평가 관련 RAG 검색 중 오류 발생: {e} !!!\")\n",
    "            print(\"벡터 스토어 로드 상태, 임베딩 모델, API 키 등을 확인하세요.\")\n",
    "            rag_context_text = \"오류 발생: 평가 참고 자료 검색 실패\"\n",
    "    else:\n",
    "        print(\"RAG 벡터 스토어가 로드되지 않았습니다. 평가 시 RAG 검색을 수행하지 않습니다.\")\n",
    "\n",
    "\n",
    "    # JSON 문자열로 변환하여 프롬프트에 포함할 문제점 후보 목록 준비\n",
    "    problem_candidates_json_string = json.dumps(problem_candidates, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # --- 프롬프트 메시지 구성 ---\n",
    "    message = evaluation_template_problem_rag.format(\n",
    "        problem_candidates_json_string=problem_candidates_json_string,\n",
    "        analysis_target_text_chunks=analysis_text_for_prompt,\n",
    "        previous_full_summary_chunks=previous_summary_for_prompt,\n",
    "        rag_context=rag_context_text if rag_context_text else \"참고 자료 없음.\"\n",
    "    )\n",
    "\n",
    "    # API 호출 (평가 실행)\n",
    "    print(\"\\n--- GPT 문제점 평가 시작 (ToT 평가) ---\")\n",
    "    try:\n",
    "        response_json = request_gpt(\n",
    "            message,\n",
    "             model=model,\n",
    "            temperature=evaluation_temperature,\n",
    "            type=\"json_object\"\n",
    "        )\n",
    "\n",
    "        evaluated_problems = response_json.get(\"평가_결과\", [])\n",
    "        if not evaluated_problems:\n",
    "            print(\"!!! 문제점 평가 결과가 비어있습니다. 또는 응답 형식이 올바르지 않습니다. !!!\")\n",
    "            print(f\"Raw Response Sample: {str(response_json)[:200]}...\")\n",
    "            fallback_evaluated = []\n",
    "            for i, p in enumerate(problem_candidates):\n",
    "                original_p = next((item for item in problem_candidates if item.get('id') == p.get('id')), {})\n",
    "                fallback_evaluated.append({\n",
    "                    \"id\": p.get(\"id\", i),\n",
    "                    \"문제점_요약\": original_p.get(\"문제점_요약\", \"N/A\"),\n",
    "                    \"문제의_심각성\": 0, \"실제_발생_가능성\": 0, \"약관_표현의_모호성_정도\": 0, \"총점\": -999,\n",
    "                    \"평가_이유_요약\": \"평가 오류 또는 결과 없음\"\n",
    "                })\n",
    "            return fallback_evaluated\n",
    "\n",
    "\n",
    "        print(\"평가 결과:\")\n",
    "        sorted_eval_results = sorted(evaluated_problems, key=lambda x: x.get('총점', 0), reverse=True)\n",
    "        for ep in sorted_eval_results:\n",
    "            이유_display = ep.get('평가_이유_요약', 'N/A')\n",
    "            print(f\"- 요약: {ep.get('문제점_요약', 'N/A')}: 총점 {ep.get('총점', 'N/A')}점 (심각성: {ep.get('문제의_심각성', 'N/A')}, 가능성: {ep.get('실제_발생_가능성', 'N/A')}, 모호성: {ep.get('약관_표현의_모호성_정도', 'N/A')}) - 이유: {이유_display}\")\n",
    "\n",
    "\n",
    "        problem_map = {p.get('id'): p for p in problem_candidates}\n",
    "        combined_results = []\n",
    "        for eval_res in evaluated_problems:\n",
    "            original_problem = problem_map.get(eval_res.get('id'))\n",
    "            if original_problem:\n",
    "                combined_results.append({**original_problem, **eval_res})\n",
    "        return combined_results\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! 오류: GPT 문제점 평가 중 오류 발생 !!!\")\n",
    "        print(f\"오류 내용: {e}\")\n",
    "        print(\"GPT API 호출 중 문제 발생. API 키, 모델 이름, 토큰 제한 등을 확인하세요.\")\n",
    "        return []\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "2dmeKpB5plGw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275275546,
     "user_tz": -540,
     "elapsed": 84,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2 결과 JSON 파일들이 모여 있는 폴더 경로\n",
    "step2_results_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/step2_results\" # 예시 경로\n",
    "\n",
    "# 약관 원문 파일들이 모여 있는 폴더 경로 (확장자는 .txt)\n",
    "terms_original_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/data/보험약관\" # 예시 경로\n",
    "\n",
    "# 약관 요약본 파일들이 모여 있는 폴더 경로 (확장자는 _summary.txt)\n",
    "summary_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/data/보험약관/summary\" # 예시 경로\n",
    "\n",
    "# Step 3 평가 결과 저장 폴더 경로\n",
    "save_folder = \"/content/drive/MyDrive/PROJECT/cn_api_project/step3_results\" # 예시 경로"
   ],
   "metadata": {
    "id": "_26zWFy6r4Rp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749275280364,
     "user_tz": -540,
     "elapsed": 6,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if save_folder: # 평가 결과 저장 폴더가 유효하면 진행\n",
    "    print(f\"\\n--- Step 2 결과 파일 순회 및 Step 3 평가 시작: '{step2_results_folder}' ---\")\n",
    "\n",
    "    # STEP2_RESULTS_DIR 대신 step2_results_folder 사용\n",
    "    json_files_in_step2 = [f for f in os.listdir(step2_results_folder) if f.lower().endswith('.json')]\n",
    "\n",
    "    if not json_files_in_step2:\n",
    "        print(f\"\\n경고: '{step2_results_folder}' 폴더에 .json 파일이 없습니다. 평가를 진행할 수 없습니다.\")\n",
    "\n",
    "    for filename in tqdm(json_files_in_step2, desc=\"파일별 문제점 평가 진행\"):\n",
    "        step2_result_file_path = os.path.join(step2_results_folder, filename)\n",
    "\n",
    "        # --- Step 2 결과 파일 이름에서 원본 파일 이름 추출 ---\n",
    "        # Step 2 결과 파일 이름 형태: problems_[보험상품이름].json (사용자 설명 기준)\n",
    "        # 또는 _problem_candidates.json 으로 끝나는 형태일 수 있습니다.\n",
    "        # 여기서 name_part_base는 [보험상품이름] 부분이 되어야 합니다.\n",
    "        name_part_base = filename.replace(\".json\", \"\") # .json 확장자 제거\n",
    "        # 'problems_' 접두사가 있다면 제거\n",
    "        if name_part_base.startswith(\"problems_\"):\n",
    "             name_part_base = name_part_base[len(\"problems_\"):]\n",
    "        # 혹시 다른 패턴 (예: _problem_candidates, _summary)이 남아있다면 제거 (안전 장치)\n",
    "        name_part_base = name_part_base.replace(\"_problem_candidates\", \"\")\n",
    "        name_part_base = name_part_base.replace(\"_summary\", \"\")\n",
    "        name_part_base = name_part_base.replace(\"_problems\", \"\") # 혹시 problems 패턴도 있다면 추가\n",
    "\n",
    "\n",
    "        # --- 해당 원본 약관 원문 텍스트 파일 경로 구성 및 로드 ---\n",
    "        # 원본 파일 이름 형태: [보험상품이름].txt\n",
    "        original_terms_filename = f\"{name_part_base}.txt\"\n",
    "        original_terms_file_path = os.path.join(terms_original_folder, original_terms_filename)\n",
    "\n",
    "        # --- 해당 약관 요약본 텍스트 파일 경로 구성 및 로드 ---\n",
    "        # 요약본 파일 이름 형태: [보험상품이름]_summary.txt\n",
    "        summary_filename = f\"{name_part_base}_summary.txt\"\n",
    "        summary_file_path = os.path.join(summary_folder, summary_filename)\n",
    "\n",
    "\n",
    "        print(f\"\\n\\n📄 평가 대상 파일: '{filename}'. 해당 원본 약관: '{original_terms_filename}'. 해당 요약본: '{summary_filename}'\")\n",
    "\n",
    "        # 약관 원문 전체 및 이전 요약 전체 텍스트 로드\n",
    "        analysis_target_text_full = load_text_file(original_terms_file_path)\n",
    "        previous_full_summary_text = load_text_file(summary_file_path)\n",
    "\n",
    "        if not analysis_target_text_full:\n",
    "             print(f\"❌ 오류: 해당 원본 약관 파일 로드 실패. 이 파일의 평가는 건너뜁니다.\")\n",
    "             continue\n",
    "\n",
    "        if not previous_full_summary_text:\n",
    "             print(f\"!!! 경고: 해당 약관 요약본 파일 로드 실패. 이전 요약 없이 평가를 진행합니다.\")\n",
    "             # 이전 요약 없더라도 평가 진행 가능하므로 continue 대신 경고만 출력\n",
    "\n",
    "\n",
    "        # --- Step 2 결과 (문제점 후보 목록) 로드 ---\n",
    "        loaded_problem_candidates = []\n",
    "        try:\n",
    "            # Step 2 결과 JSON 파일에서 문제점 후보 목록 로드\n",
    "            # load_json_file 함수를 사용하거나 여기서 직접 open/json.load\n",
    "            # load_json_file 함수가 정의되어 있다면 사용\n",
    "            loaded_problem_candidates = load_json_file(step2_result_file_path)\n",
    "            if loaded_problem_candidates is None:\n",
    "                print(f\"❌ 오류: Step 2 결과 파일 로드 또는 파싱 실패 ({filename}).\")\n",
    "                loaded_problem_candidates = [] # 로드 실패 시 빈 리스트\n",
    "\n",
    "            # 문제점 후보 목록이 예상치 못한 형태 (예: 딕셔너리)인 경우 리스트로 변환 시도\n",
    "            if not isinstance(loaded_problem_candidates, list):\n",
    "                 print(f\"경고: Step 2 결과 파일 내용이 리스트 형태가 아닙니다. 데이터 확인 필요 ({filename}).\")\n",
    "                 # 단일 딕셔너리 형태라면 리스트로 감싸서 처리\n",
    "                 if isinstance(loaded_problem_candidates, dict):\n",
    "                      # 딕셔너리 안에 '잠재적_문제점_후보' 키가 있다면 해당 리스트 사용\n",
    "                      if '잠재적_문제점_후보' in loaded_problem_candidates and isinstance(loaded_problem_candidates['잠재적_문제점_후보'], list):\n",
    "                           loaded_problem_candidates = loaded_problem_candidates['잠재적_문제점_후보']\n",
    "                           print(f\"  - '잠재적_문제점_후보' 키 아래 리스트 {len(loaded_problem_candidates)}개 로드 완료.\")\n",
    "                      else:\n",
    "                           print(f\"  - Step 2 결과 파일 내용이 예상치 못한 딕셔너리 형태입니다. 로드 실패.\")\n",
    "                           loaded_problem_candidates = [] # 예상치 못한 형태면 빈 리스트\n",
    "                 else:\n",
    "                     loaded_problem_candidates = [] # 예상치 못한 형태면 빈 리스트\n",
    "\n",
    "\n",
    "            print(f\"  - Step 2 결과 로드 완료. 문제점 후보 {len(loaded_problem_candidates)}개.\")\n",
    "        except Exception as e: # load_json_file 함수 자체 오류 등\n",
    "            print(f\"❌ 오류: Step 2 결과 파일 로드 중 예외 발생 ({filename}): {e}\")\n",
    "            loaded_problem_candidates = []\n",
    "\n",
    "\n",
    "        # --- Step 3 문제점 평가 실행 ---\n",
    "        if loaded_problem_candidates:\n",
    "            print(\"  - 문제점 평가 함수 호출 중...\")\n",
    "            # evaluate_problems_with_rag 함수 호출\n",
    "            evaluated_problem_results = evaluate_problems_with_rag(\n",
    "                problem_candidates=loaded_problem_candidates, # 평가 대상 문제점 후보 목록 전달\n",
    "                analysis_target_text_full=analysis_target_text_full, # 약관 원문 전체 전달\n",
    "                previous_full_summary_text=previous_full_summary_text, # 이전 요약 전체 전달\n",
    "                rag_vectorstore=rag_vectorstore, # 로드된 벡터 스토어 전달 (평가 시 RAG 활용)\n",
    "                model=\"gpt-4o-2024-05-13\" # GPT 모델\n",
    "            )\n",
    "\n",
    "            print(f\"  - 문제점 평가 함수 실행 완료. 평가 결과 {len(evaluated_problem_results)}개.\")\n",
    "\n",
    "            # --- 평가 결과 저장 파일 이름 자동 생성 및 저장 ---\n",
    "            if evaluated_problem_results:\n",
    "                # 저장될 파일 이름 자동 생성 (evaluation_ + 원본이름 + .json)\n",
    "                evaluation_filename = f\"evaluation_{name_part_base}.json\"\n",
    "                save_path = os.path.join(save_folder, evaluation_filename)\n",
    "\n",
    "                print(f\"  - 평가 결과 JSON 파일 저장 중: '{evaluation_filename}'\")\n",
    "                try:\n",
    "                    with open(save_path, 'w', encoding='utf-8') as out_file:\n",
    "                        json.dump(evaluated_problem_results, out_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "                    print(f\"✅ 저장 완료: '{evaluation_filename}'\")\n",
    "\n",
    "                except IOError as e:\n",
    "                    print(f\"❌ 파일 저장 오류 ({evaluation_filename}): {e}\")\n",
    "                    print(f\"경로 확인: '{save_path}' 경로에 쓸 수 있는지, Google Drive 마운트 상태가 올바른지 확인하세요.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"경고: '{filename}' 파일에 대해 생성된 평가 결과가 없습니다.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"경고: '{filename}' 파일에서 로드된 문제점 후보가 없어 평가를 건너뜁니다.\")\n",
    "\n",
    "print(\"\\n--- 파일 순회 완료 ---\")\n",
    "\n",
    "# else:\n",
    "#    print(\"\\n--- Step 3 실행 불가 ---\")\n",
    "\n",
    "if not os.path.exists(step2_results_folder):\n",
    "    print(f\"Step 2 결과 폴더를 찾을 수 없습니다: '{step2_results_folder}'\")\n",
    "if not os.path.exists(terms_original_folder):\n",
    "    print(f\"약관 원문 폴더를 찾을 수 없습니다: '{terms_original_folder}'\")\n",
    "if not os.path.exists(summary_folder):\n",
    "    print(f\"약관 요약본 폴더를 찾을 수 없습니다: '{summary_folder}'\")\n",
    "if rag_vectorstore is None:\n",
    "    print(\"벡터 스토어가 로드되지 않았습니다. Step 0 실행 및 영구 저장 확인 필요.\")\n",
    "if llm is None:\n",
    "    print(\"GPT 모델 로드 오류가 발생했습니다. API 키 설정 또는 모델 이름 확인 필요.\")\n",
    "\n",
    "print(\"\\n### Step 3 평가 프로세스 완료. ###\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670,
     "referenced_widgets": [
      "47d7ea1375844c53ba4b5f25fe0db810",
      "b42f6f289c034efeb0e5696171e17330",
      "766cc6cc3bc94bc6afa591c4a09e337f",
      "d132acf10a9c451e865047355efac840",
      "44bb7f8cb78347209844bb2463e1a8be",
      "69581083f3114faba53831a062b4410d",
      "7ca2a2fad6894e41b61f24f108e29673",
      "15f72fc27a544278b69d7d08f91eb781",
      "3994845a159842389e163f37ec28102b",
      "b77534256c7e4eeabf499a9fa480679f",
      "cfb735fd7eff413bab561291ef9e19d1"
     ]
    },
    "id": "cKy2wOwysBcM",
    "executionInfo": {
     "status": "error",
     "timestamp": 1749275286679,
     "user_tz": -540,
     "elapsed": 4959,
     "user": {
      "displayName": "Junhee Choi",
      "userId": "01054653513821718568"
     }
    },
    "outputId": "83a18dd4-b5ac-473d-b646-bb138db3b8f6"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Step 2 결과 파일 순회 및 Step 3 평가 시작: '/content/drive/MyDrive/PROJECT/cn_api_project/step2_results' ---\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "파일별 문제점 평가 진행:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47d7ea1375844c53ba4b5f25fe0db810"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "📄 평가 대상 파일: 'problems_한화_스마일펫보험.json'. 해당 원본 약관: '한화_스마일펫보험.txt'. 해당 요약본: '한화_스마일펫보험_summary.txt'\n",
      "  - Step 2 결과 로드 완료. 문제점 후보 227개.\n",
      "  - 문제점 평가 함수 호출 중...\n",
      "\n",
      "--- [Step 3] 잠재적 문제점 평가 (227개 후보 대상, RAG 활용 가능) ---\n",
      "약관 원문 전체 텍스트 (57259자) 평가용 청크 32개 생성.\n",
      "이전 요약 전체 텍스트 (65362자) 평가용 청크 76개 생성.\n",
      "\n",
      "--- 평가 관련 RAG 검색 시작 ---\n",
      "!!! 오류: 평가 관련 RAG 검색 중 오류 발생: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}} !!!\n",
      "벡터 스토어 로드 상태, 임베딩 모델, API 키 등을 확인하세요.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'analysis_target_text'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-8a0a07a5ff14>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     88\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"  - 문제점 평가 함수 호출 중...\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m             \u001B[0;31m# evaluate_problems_with_rag 함수 호출\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 90\u001B[0;31m             evaluated_problem_results = evaluate_problems_with_rag(\n\u001B[0m\u001B[1;32m     91\u001B[0m                 \u001B[0mproblem_candidates\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mloaded_problem_candidates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m# 평가 대상 문제점 후보 목록 전달\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m                 \u001B[0manalysis_target_text_full\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0manalysis_target_text_full\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m# 약관 원문 전체 전달\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-8d2eca4a95c0>\u001B[0m in \u001B[0;36mevaluate_problems_with_rag\u001B[0;34m(problem_candidates, analysis_target_text_full, previous_full_summary_text, rag_vectorstore, model)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[0;31m# --- 프롬프트 메시지 구성 ---\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m     message = evaluation_template_problem_rag.format(\n\u001B[0m\u001B[1;32m     94\u001B[0m         \u001B[0mproblem_candidates_json_string\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mproblem_candidates_json_string\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0manalysis_target_text_chunks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0manalysis_text_for_prompt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'analysis_target_text'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "LJO3C-QCsBgn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "m3w0r8MLsBi_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YW0r8feqsBk-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def batch_problem_evaluation(\n",
    "    problem_candidates: list,\n",
    "    analysis_target_text_full: str,  # RAG 전용, 직접 넣지 않음\n",
    "    previous_full_summary_text: str,\n",
    "    rag_vectorstore,\n",
    "    batch_size: int = 20\n",
    "):\n",
    "    all_results = []\n",
    "    for i in range(0, len(problem_candidates), batch_size):\n",
    "        batch = problem_candidates[i:i+batch_size]\n",
    "        try:\n",
    "            results = evaluate_problems_with_rag(\n",
    "                problem_candidates=batch,\n",
    "                analysis_target_text_full=\"\",  # 직접 넣지 않음 (벡터스토어에서만 검색)\n",
    "                previous_full_summary_text=previous_full_summary_text,\n",
    "                rag_vectorstore=rag_vectorstore\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류 발생 (batch {i}~{i+batch_size}): {e}\")\n",
    "    return all_results"
   ],
   "metadata": {
    "id": "ckz1gVJdqOh4"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
